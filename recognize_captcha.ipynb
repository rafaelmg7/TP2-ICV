{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb18e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca1c76d",
   "metadata": {},
   "source": [
    "## Limpar Pastas que não serão usadas mais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc47777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conjuntos = ['treinamento', 'teste', 'validacao']\n",
    "base_path = '/home/bernardo/TP2-ICV/dados/processed'\n",
    "pastas_excluir = ['cleanImage', '?']\n",
    "\n",
    "for conjunto in conjuntos:\n",
    "    conjunto_path = os.path.join(base_path, conjunto)\n",
    "    for nome in os.listdir(conjunto_path):\n",
    "        full_path = os.path.join(conjunto_path, nome)\n",
    "        if nome in pastas_excluir and os.path.isdir(full_path):\n",
    "            print(f\"Removendo pasta: {full_path}\")\n",
    "            shutil.rmtree(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245cea59",
   "metadata": {},
   "source": [
    "## Carregar os datasets a partir das pastas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf89ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47868 files belonging to 36 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-22 09:58:02.915700: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5994 files belonging to 36 classes.\n",
      "Found 5994 files belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'dados/processed/treinamento'\n",
    "val_dir   = 'dados/processed/validacao'\n",
    "test_dir  = 'dados/processed/teste'\n",
    "\n",
    "batch_size = 32\n",
    "img_size = (36, 50)\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    label_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    label_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    label_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5791b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Input(shape=img_size + (1,)),\n",
    "    layers.Rescaling(1./255), \n",
    "\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(train_ds.element_spec[1].shape[1], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe520e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m 158/1496\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:31\u001b[0m 203ms/step - accuracy: 0.0702 - loss: 3.4319"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Treinamento\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc53ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"\\nTest accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Gráficos\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Treinamento')\n",
    "plt.plot(epochs_range, val_acc, label='Validação')\n",
    "plt.title('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Treinamento')\n",
    "plt.plot(epochs_range, val_loss, label='Validação')\n",
    "plt.title('Erro (Loss)')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
